{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Fl1Gz7vzKt",
        "outputId": "3284159c-a34b-40b7-f246-06f9f534577e"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o1IR2qgv4F0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from timm import create_model\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from ptflops import get_model_complexity_info\n",
        "import torchvision.models as models\n",
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "LR_HYBRID = 1e-4\n",
        "LR_VIT = 1e-4\n",
        "LR_RESNET = 1e-4\n",
        "EPOCHS = 200\n",
        "IMG_SIZE_HYBRID = 224\n",
        "IMG_SIZE_VIT_RESNET = 224\n",
        "NUM_CLASSES = 4\n",
        "SEED = 42\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU-0ZFZyw93N"
      },
      "outputs": [],
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=0.05):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "# Define transforms\n",
        "transform_hybrid = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((IMG_SIZE_HYBRID, IMG_SIZE_HYBRID)),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE_HYBRID, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomApply([\n",
        "        transforms.RandomAffine(\n",
        "            degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05), shear=5\n",
        "        )\n",
        "    ], p=0.5),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.1),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    AddGaussianNoise(0., 0.05),  # Custom transform, see above\n",
        "    transforms.Normalize([0.5], [0.5]),\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.01, 0.05), ratio=(0.3, 3.3), value='random')\n",
        "])\n",
        "\n",
        "\n",
        "transform_vit_resnet = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((IMG_SIZE_VIT_RESNET, IMG_SIZE_VIT_RESNET)),  \n",
        "    transforms.RandomResizedCrop(IMG_SIZE_VIT_RESNET, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomApply([\n",
        "        transforms.RandomAffine(\n",
        "            degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05), shear=5\n",
        "        )\n",
        "    ], p=0.5),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.1),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    AddGaussianNoise(0., 0.05),  # Custom transform, see above\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.01, 0.05), ratio=(0.3, 3.3), value='random'),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "data_dir = 'brain-tumor-mri-dataset'\n",
        "full_dataset = datasets.ImageFolder(f'{data_dir}/Training', transform=transform_hybrid)\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "train_size = len(full_dataset) - val_size\n",
        "train_ds_hybrid, val_ds_hybrid = random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(SEED))\n",
        "test_ds_hybrid = datasets.ImageFolder(f'{data_dir}/Testing', transform=transform_hybrid)\n",
        "\n",
        "# For ViT/ResNet, reload with different transform\n",
        "full_dataset_vit = datasets.ImageFolder(f'{data_dir}/Training', transform=transform_vit_resnet)\n",
        "train_ds_vit, val_ds_vit = random_split(full_dataset_vit, [train_size, val_size], generator=torch.Generator().manual_seed(SEED))\n",
        "test_ds_vit = datasets.ImageFolder(f'{data_dir}/Testing', transform=transform_vit_resnet)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader_hybrid = DataLoader(train_ds_hybrid, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader_hybrid = DataLoader(val_ds_hybrid, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader_hybrid = DataLoader(test_ds_hybrid, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "train_loader_vit = DataLoader(train_ds_vit, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader_vit = DataLoader(val_ds_vit, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader_vit = DataLoader(test_ds_vit, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Train samples (Hybrid): {len(train_loader_hybrid.dataset)}\")\n",
        "print(f\"Validation samples (Hybrid): {len(val_loader_hybrid.dataset)}\")\n",
        "print(f\"Test samples (Hybrid): {len(test_loader_hybrid.dataset)}\")\n",
        "\n",
        "print(f\"Train samples (ViT/ResNet): {len(train_loader_vit.dataset)}\")\n",
        "print(f\"Validation samples (ViT/ResNet): {len(val_loader_vit.dataset)}\")\n",
        "print(f\"Test samples (ViT/ResNet): {len(test_loader_vit.dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow(img_tensor, title=None):\n",
        "    # img_tensor shape: [C, H, W]\n",
        "    img = img_tensor.numpy().transpose((1, 2, 0))  # H, W, C\n",
        "    # For grayscale, squeeze channel dim\n",
        "    if img.shape[2] == 1:\n",
        "        img = img.squeeze(axis=2)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Get one batch of images\n",
        "dataiter = iter(train_loader_hybrid)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Denormalize: images were normalized with mean=0.5, std=0.5\n",
        "images = images * 0.5 + 0.5  # reverse normalization\n",
        "\n",
        "# Plot a few images\n",
        "for i in range(4):\n",
        "    imshow(images[i], title=f'Label: {labels[i].item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow_rgb(img_tensor, title=None):\n",
        "    img = img_tensor.numpy().transpose((1, 2, 0))  # H, W, C\n",
        "    plt.imshow(img)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "dataiter_vit = iter(train_loader_vit)\n",
        "images_vit, labels_vit = next(dataiter_vit)\n",
        "images_vit = images_vit * 0.5 + 0.5  # Denormalize\n",
        "\n",
        "for i in range(4):\n",
        "    imshow_rgb(images_vit[i], title=f'Label: {labels_vit[i].item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --- Channel Attention ---\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_channels // reduction, in_channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "# --- Spatial Attention ---\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=3, padding=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.sigmoid(self.conv(x))\n",
        "\n",
        "# --- CNN Tokenizer with CBAM ---\n",
        "class PowerfulCNNTokenizer(nn.Module):\n",
        "    def __init__(self, in_channels=1, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 112x112\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 56x56\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 28x28\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 14x14\n",
        "        )\n",
        "        self.channel_attention = ChannelAttention(256)\n",
        "        self.spatial_attention = SpatialAttention(256)\n",
        "        self.project = nn.Conv2d(256, hidden_dim, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.channel_attention(x)\n",
        "        x = self.spatial_attention(x)\n",
        "        x = self.project(x)\n",
        "        B, C, H, W = x.shape\n",
        "        return x.flatten(2).transpose(1, 2)  # (B, N_tokens, hidden_dim)\n",
        "\n",
        "# --- Transformer Encoder ---\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, dim=256, depth=4, heads=4, mlp_dim=512):\n",
        "        super().__init__()\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, 197, dim))  # 196 + 1\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=dim, nhead=heads, dim_feedforward=mlp_dim,\n",
        "                activation='gelu', batch_first=True\n",
        "            ) for _ in range(depth)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, D = x.shape\n",
        "        cls_tokens = self.cls_token.expand(B, 1, D)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.pos_embedding[:, :x.size(1), :]\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return self.norm(x)  # (B, N+1, D)\n",
        "\n",
        "# --- Attention Pooling ---\n",
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):  # (B, N, D)\n",
        "        weights = F.softmax(self.attn(x), dim=1)  # (B, N, 1)\n",
        "        return (weights * x).sum(dim=1)  # (B, D)\n",
        "\n",
        "# --- Final Classifier ---\n",
        "class HybridTumorClassifier(nn.Module):\n",
        "    def __init__(self, in_channels=1, hidden_dim=256, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.tokenizer = PowerfulCNNTokenizer(in_channels=in_channels, hidden_dim=hidden_dim)\n",
        "        self.transformer = TransformerEncoder(dim=hidden_dim, depth=4, heads=4, mlp_dim=512)\n",
        "        self.attn_pool = AttentionPooling(hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tokenizer(x)              # (B, 196, D)\n",
        "        x = self.transformer(x)           # (B, 197, D)\n",
        "        x = self.attn_pool(x)             # (B, D)\n",
        "        x = self.dropout(x)\n",
        "        return self.head(x)               # (B, num_classes)\n",
        "\n",
        "# --- Run test ---\n",
        "if __name__ == \"__main__\":\n",
        "    model = HybridTumorClassifier(in_channels=1, num_classes=4)\n",
        "    dummy_input = torch.randn(2, 1, 224, 224)\n",
        "    output = model(dummy_input)\n",
        "    print(\"Output shape:\", output.shape)  # Expected: (2, 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0.0, mode='min'):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.mode = mode\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, metric):\n",
        "        # Adjust for minimization\n",
        "        score = -metric if self.mode == 'min' else metric\n",
        "        if self.best_score is None or score > self.best_score + self.min_delta:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "\n",
        "def train_model(model, optimizer, name, train_loader, val_loader, epochs=EPOCHS):\n",
        "    device = next(model.parameters()).device\n",
        "    early_stopper = EarlyStopping(patience=15, mode='min')  # Changed mode to 'min'\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.01)\n",
        "    best_val_loss = float('inf')  # Changed to track loss\n",
        "    best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    train_accs, val_accs = [], []\n",
        "    train_losses, val_losses = [], []\n",
        "    train_precisions, val_precisions = [], []\n",
        "    train_recalls, val_recalls = [], []\n",
        "    train_f1s, val_f1s = [], []\n",
        "    train_aucs, val_aucs = [], []\n",
        "    \n",
        "    scaler = GradScaler()  # Initialize GradScaler for mixed precision training\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_correct, train_total, train_loss = 0, 0, 0.0\n",
        "        train_preds, train_labels = [], []\n",
        "        train_probs = []  # To store probabilities\n",
        "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
        "        for imgs, labels in train_bar:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixed Precision: Wrap forward pass and loss calculation in autocast\n",
        "            with autocast(device_type='cuda'):  # Updated to use 'cuda'\n",
        "                outputs = model(imgs)\n",
        "                probs = torch.softmax(outputs, dim=1)  # Get probabilities\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scale the loss and perform backpropagation\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss += loss.item() * imgs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            train_correct += (preds == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "            train_preds.extend(preds.cpu().numpy())\n",
        "            train_labels.extend(labels.cpu().numpy())\n",
        "            train_probs.extend(probs.detach().cpu().numpy())  # Store probabilities\n",
        "            train_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_acc = train_correct / train_total\n",
        "        train_loss /= train_total\n",
        "\n",
        "        # Calculate additional metrics for train\n",
        "        train_precision = precision_score(train_labels, train_preds, average='macro', zero_division=1)\n",
        "        train_recall = recall_score(train_labels, train_preds, average='macro', zero_division=1)\n",
        "        train_f1 = f1_score(train_labels, train_preds, average='macro', zero_division=1)\n",
        "        train_auc = roc_auc_score(train_labels, train_probs, average='macro', multi_class='ovo')  # For multi-class\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct, val_total, val_loss = 0, 0, 0.0\n",
        "        val_preds, val_labels = [], []\n",
        "        val_probs = []  # To store probabilities\n",
        "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_bar:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "                outputs = model(imgs)\n",
        "                probs = torch.softmax(outputs, dim=1)  # Get probabilities\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * imgs.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "                val_probs.extend(probs.detach().cpu().numpy())  # Store probabilities\n",
        "                val_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "        val_loss /= val_total\n",
        "\n",
        "        # Calculate additional metrics for validation\n",
        "        val_precision = precision_score(val_labels, val_preds, average='macro', zero_division=1)\n",
        "        val_recall = recall_score(val_labels, val_preds, average='macro', zero_division=1)\n",
        "        val_f1 = f1_score(val_labels, val_preds, average='macro', zero_division=1)\n",
        "        val_auc = roc_auc_score(val_labels, val_probs, average='macro', multi_class='ovo')  # For multi-class\n",
        "        \n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_precisions.append(train_precision)\n",
        "        val_precisions.append(val_precision)\n",
        "        train_recalls.append(train_recall)\n",
        "        val_recalls.append(val_recall)\n",
        "        train_f1s.append(train_f1)\n",
        "        val_f1s.append(val_f1)\n",
        "        train_aucs.append(train_auc)\n",
        "        val_aucs.append(val_auc)\n",
        "\n",
        "        # Save best model based on val_loss now\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Remove the val_loss argument from scheduler.step()\n",
        "        scheduler.step()  # No arguments now\n",
        "        early_stopper(val_loss)  # Now monitoring val_loss\n",
        "        if early_stopper.early_stop:\n",
        "            print(\"Early stopping triggered!\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(best_weights)\n",
        "    return model, best_val_loss, {  # Returning best_val_loss instead of best_val_acc\n",
        "        \"train_accs\": train_accs,\n",
        "        \"val_accs\": val_accs,\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"train_precisions\": train_precisions,\n",
        "        \"val_precisions\": val_precisions,\n",
        "        \"train_recalls\": train_recalls,\n",
        "        \"val_recalls\": val_recalls,\n",
        "        \"train_f1s\": train_f1s,\n",
        "        \"val_f1s\": val_f1s,\n",
        "        \"train_aucs\": train_aucs,\n",
        "        \"val_aucs\": val_aucs\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_and_report(model, name, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    all_probs = []  # To store probabilities\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs, labels = imgs.to(next(model.parameters()).device), labels.to(next(model.parameters()).device)\n",
        "            outputs = model(imgs)\n",
        "            probs = torch.softmax(outputs, dim=1)  # Get probabilities\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())  # Store probabilities\n",
        "            \n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    print(f\"{name} Test Accuracy: {acc:.4f}\")\n",
        "    \n",
        "    # Generate Classification Report (Precision, Recall, F1-Score)\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    print(f\"{name} Classification Report: {report}\")\n",
        "    \n",
        "    # Compute ROC-AUC\n",
        "    auc = roc_auc_score(all_labels, all_probs, average='macro', multi_class='ovo')  # Use `all_probs` for AUC\n",
        "    print(f\"{name} Test ROC-AUC: {auc:.4f}\")\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_loader.dataset.classes)\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    return acc, report, auc, cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_model(model, input_res=(1, 128, 128), device=device):\n",
        "    model.eval()\n",
        "    with torch.cuda.device(0 if device == 'cuda' else -1):\n",
        "        flops, params = get_model_complexity_info(\n",
        "            model, input_res, as_strings=True,\n",
        "            print_per_layer_stat=False, verbose=False\n",
        "        )\n",
        "    print(f\"\\n📊 Model Analysis:\")\n",
        "    print(f\"Input resolution: {input_res}\")\n",
        "    print(f\"FLOPs: {flops}\")\n",
        "    print(f\"Parameters: {params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aBZagzO1_H4"
      },
      "outputs": [],
      "source": [
        "# ViT\n",
        "model_vit = create_model('vit_base_patch16_224', pretrained=True, num_classes=NUM_CLASSES)\n",
        "model_vit = model_vit.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ResNet\n",
        "model_resnet = models.resnet50(pretrained=True)\n",
        "model_resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "model_resnet.fc = nn.Linear(model_resnet.fc.in_features, NUM_CLASSES)\n",
        "model_resnet = model_resnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DenseNet121\n",
        "model_densenet = models.densenet121(pretrained=True)\n",
        "model_densenet.classifier = nn.Linear(model_densenet.classifier.in_features, NUM_CLASSES)\n",
        "model_densenet = model_densenet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EfficientNetV2-M\n",
        "model_effnetv2 = create_model('efficientnetv2_m', pretrained=False, num_classes=NUM_CLASSES)\n",
        "model_effnetv2 = model_effnetv2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ConvNeXt-Base\n",
        "model_convnext = create_model('convnext_base', pretrained=True, num_classes=NUM_CLASSES)\n",
        "model_convnext = model_convnext.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RegNetY-032\n",
        "model_regnet = create_model('regnety_032', pretrained=True, num_classes=NUM_CLASSES)\n",
        "model_regnet = model_regnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Swin Transformer\n",
        "model_swin = create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=NUM_CLASSES)\n",
        "model_swin = model_swin.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MaxViT\n",
        "model_maxvit = create_model('maxvit_base_tf_224', pretrained=True, num_classes=NUM_CLASSES)\n",
        "model_maxvit = model_maxvit.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hybrid_model = HybridTumorClassifier(in_channels=1, num_classes=NUM_CLASSES).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_stats = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Hybrid Model\n",
        "hybrid_optimizer = optim.AdamW(hybrid_model.parameters(), lr=LR_HYBRID, weight_decay=1e-4)\n",
        "start = time.time()\n",
        "hybrid_model, hybrid_val_loss, hybrid_stats = train_model(\n",
        "    hybrid_model, hybrid_optimizer, name='Hybrid', train_loader=train_loader_hybrid, val_loader=val_loader_hybrid)\n",
        "hybrid_test_acc, hybrid_report, hybrid_auc, hybrid_cm = test_and_report(hybrid_model, 'Hybrid', test_loader_hybrid)\n",
        "models_stats['Hybrid'] = hybrid_stats\n",
        "\n",
        "# 2. ViT Model\n",
        "start = time.time()\n",
        "vit_optimizer = optim.AdamW(model_vit.parameters(), lr=LR_VIT)\n",
        "model_vit, vit_val_loss, vit_stats = train_model(\n",
        "    model_vit, vit_optimizer, name='ViT', train_loader=train_loader_vit, val_loader=val_loader_vit)\n",
        "vit_test_acc, vit_report, vit_auc, vit_cm = test_and_report(model_vit, 'ViT', test_loader_vit)\n",
        "models_stats['ViT'] = vit_stats\n",
        "\n",
        "# 3. ResNet Model\n",
        "start = time.time()\n",
        "resnet_optimizer = optim.Adam(model_resnet.parameters(), lr=LR_RESNET)\n",
        "model_resnet, resnet_val_loss, resnet_stats = train_model(\n",
        "    model_resnet, resnet_optimizer, name='ResNet', train_loader=train_loader_vit, val_loader=val_loader_vit)\n",
        "resnet_test_acc, resnet_report, resnet_auc, resnet_cm = test_and_report(model_resnet, 'ResNet', test_loader_vit)\n",
        "models_stats['ResNet'] = resnet_stats\n",
        "\n",
        "# 4. DenseNet121 Model\n",
        "start = time.time()\n",
        "densenet_optimizer = optim.AdamW(model_densenet.parameters(), lr=LR_HYBRID, weight_decay=1e-4)\n",
        "model_densenet, densenet_val_loss, densenet_stats = train_model(\n",
        "    model_densenet, densenet_optimizer, name='DenseNet121', train_loader=train_loader_vit, val_loader=val_loader_vit)\n",
        "densenet_test_acc, densenet_report, densenet_auc, densenet_cm = test_and_report(model_densenet, 'DenseNet121', test_loader_vit)\n",
        "models_stats['DenseNet121'] = densenet_stats\n",
        "\n",
        "# 5. RegNetY-032 Model\n",
        "start = time.time()\n",
        "regnet_optimizer = optim.AdamW(model_regnet.parameters(), lr=LR_HYBRID, weight_decay=1e-4)\n",
        "model_regnet, regnet_val_loss, regnet_stats = train_model(\n",
        "    model_regnet, regnet_optimizer, name='RegNetY-032', train_loader=train_loader_vit, val_loader=val_loader_vit)\n",
        "regnet_test_acc, regnet_report, regnet_auc, regnet_cm = test_and_report(model_regnet, 'RegNetY-032', test_loader_vit)\n",
        "models_stats['RegNetY-032'] = regnet_stats\n",
        "\n",
        "# 6. EfficientNetV2 Model\n",
        "start = time.time()\n",
        "effnetv2_optimizer = optim.AdamW(model_effnetv2.parameters(), lr=LR_HYBRID, weight_decay=1e-4)\n",
        "model_effnetv2, effnetv2_val_loss, effnetv2_stats = train_model(\n",
        "    model_effnetv2, effnetv2_optimizer, name='EfficientNetV2', train_loader=train_loader_vit, val_loader=val_loader_vit)\n",
        "effnetv2_test_acc, effnetv2_report, effnetv2_auc, effnetv2_cm = test_and_report(model_effnetv2, 'EfficientNetV2', test_loader_vit)\n",
        "models_stats['EfficientNetV2'] = effnetv2_stats\n",
        "\n",
        "# 7. ConvNeXt Model\n",
        "start = time.time()\n",
        "convnext_optimizer = optim.AdamW(model_convnext.parameters(), lr=LR_HYBRID, weight_decay=1e-4)\n",
        "model_convnext, convnext_val_loss, convnext_stats = train_model(\n",
        "    model_convnext, convnext_optimizer, name='ConvNeXt', train_loader=train_loader_vit, val_loader=val_loader_vit)\n",
        "convnext_test_acc, convnext_report, convnext_auc, convnext_cm = test_and_report(model_convnext, 'ConvNeXt', test_loader_vit)\n",
        "models_stats['ConvNeXt'] = convnext_stats\n",
        "\n",
        "# 8. Swin Transformer Model\n",
        "start = time.time()\n",
        "swin_optimizer = optim.AdamW(model_swin.parameters(), lr=LR_HYBRID, weight_decay=1e-4)\n",
        "model_swin, swin_val_loss, swin_stats = train_model(\n",
        "    model_swin, swin_optimizer, name='Swin Transformer', train_loader=train_loader_vit, val_loader=val_loader_vit)\n",
        "swin_test_acc, swin_report, swin_auc, swin_cm = test_and_report(model_swin, 'Swin Transformer', test_loader_vit)\n",
        "models_stats['Swin Transformer'] = swin_stats\n",
        "\n",
        "# 9. MaxViT Model\n",
        "start = time.time()\n",
        "maxvit_optimizer = optim.AdamW(model_maxvit.parameters(), lr=LR_HYBRID, weight_decay=1e-4)\n",
        "model_maxvit, maxvit_val_loss, maxvit_stats = train_model(\n",
        "    model_maxvit, maxvit_optimizer, name='MaxViT', train_loader=train_loader_vit, val_loader=val_loader_vit)\n",
        "maxvit_test_acc, maxvit_report, maxvit_auc, maxvit_cm = test_and_report(model_maxvit, 'MaxViT', test_loader_vit)\n",
        "models_stats['MaxViT'] = maxvit_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n📈 Final Test Results:\")\n",
        "\n",
        "# List of all models and their corresponding names\n",
        "models = [\n",
        "    ('Hybrid', hybrid_model, test_loader_hybrid),\n",
        "    ('ViT', model_vit, test_loader_vit),\n",
        "    ('ResNet', model_resnet, test_loader_vit),\n",
        "    ('DenseNet121', model_densenet, test_loader_vit),\n",
        "    ('RegNetY-032', model_regnet, test_loader_vit),\n",
        "    ('EfficientNetV2', model_effnetv2, test_loader_vit),\n",
        "    ('ConvNeXt', model_convnext, test_loader_vit),\n",
        "    ('Swin Transformer', model_swin, test_loader_vit),\n",
        "    ('MaxViT', model_maxvit, test_loader_vit)\n",
        "]\n",
        "\n",
        "# Store test results\n",
        "test_results = []\n",
        "\n",
        "# Loop over models and collect their test accuracy\n",
        "for model_name, model, test_loader in models:\n",
        "    test_acc, report, auc, cm = test_and_report(model, model_name, test_loader)\n",
        "    \n",
        "    # Extract metrics from the classification report\n",
        "    precision = report['macro avg']['precision']\n",
        "    recall = report['macro avg']['recall']\n",
        "    f1_score = report['macro avg']['f1-score']\n",
        "    \n",
        "    test_results.append({\n",
        "        'Model': model_name,\n",
        "        'Test Accuracy': test_acc,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1_score,\n",
        "        'AUC': auc\n",
        "    })\n",
        "\n",
        "# Convert the results into a DataFrame for easier visualization\n",
        "results_df = pd.DataFrame(test_results)\n",
        "\n",
        "# Display the results\n",
        "print(results_df)\n",
        "\n",
        "# Optionally, save the results to a CSV file\n",
        "results_df.to_csv(\"final_test_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_metrics(models_stats):\n",
        "    \"\"\"\n",
        "    Plots accuracy, loss, precision, recall, F1, and AUC metrics for each model.\n",
        "    \n",
        "    :param models_stats: Dictionary containing stats for each model (e.g., accuracy, precision, etc.)\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(2, 3, 1)\n",
        "    for model_name, stats in models_stats.items():\n",
        "        plt.plot(range(1, len(stats[\"train_accs\"]) + 1), stats[\"train_accs\"], label=f'{model_name} Train')\n",
        "        plt.plot(range(1, len(stats[\"val_accs\"]) + 1), stats[\"val_accs\"], label=f'{model_name} Val')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(2, 3, 2)\n",
        "    for model_name, stats in models_stats.items():\n",
        "        plt.plot(range(1, len(stats[\"train_losses\"]) + 1), stats[\"train_losses\"], label=f'{model_name} Train')\n",
        "        plt.plot(range(1, len(stats[\"val_losses\"]) + 1), stats[\"val_losses\"], label=f'{model_name} Val')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Precision\n",
        "    plt.subplot(2, 3, 3)\n",
        "    for model_name, stats in models_stats.items():\n",
        "        plt.plot(range(1, len(stats[\"train_precisions\"]) + 1), stats[\"train_precisions\"], label=f'{model_name} Train')\n",
        "        plt.plot(range(1, len(stats[\"val_precisions\"]) + 1), stats[\"val_precisions\"], label=f'{model_name} Val')\n",
        "    plt.title('Training and Validation Precision')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Recall\n",
        "    plt.subplot(2, 3, 4)\n",
        "    for model_name, stats in models_stats.items():\n",
        "        plt.plot(range(1, len(stats[\"train_recalls\"]) + 1), stats[\"train_recalls\"], label=f'{model_name} Train')\n",
        "        plt.plot(range(1, len(stats[\"val_recalls\"]) + 1), stats[\"val_recalls\"], label=f'{model_name} Val')\n",
        "    plt.title('Training and Validation Recall')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Recall')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot F1-Score\n",
        "    plt.subplot(2, 3, 5)\n",
        "    for model_name, stats in models_stats.items():\n",
        "        plt.plot(range(1, len(stats[\"train_f1s\"]) + 1), stats[\"train_f1s\"], label=f'{model_name} Train')\n",
        "        plt.plot(range(1, len(stats[\"val_f1s\"]) + 1), stats[\"val_f1s\"], label=f'{model_name} Val')\n",
        "    plt.title('Training and Validation F1-Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1-Score')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot AUC\n",
        "    plt.subplot(2, 3, 6)\n",
        "    for model_name, stats in models_stats.items():\n",
        "        plt.plot(range(1, len(stats[\"train_aucs\"]) + 1), stats[\"train_aucs\"], label=f'{model_name} Train')\n",
        "        plt.plot(range(1, len(stats[\"val_aucs\"]) + 1), stats[\"val_aucs\"], label=f'{model_name} Val')\n",
        "    plt.title('Training and Validation AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
<<<<<<< HEAD
        "    plt.show()\n",
        "\n",
        "plot_metrics(models_stats)"
=======
        "    plt.show()\n"
>>>>>>> 0f3385d (Added function for plotting important metrics)
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze Hybrid model\n",
        "analyze_model(hybrid_model, input_res=(1, 224, 224), device=device)\n",
        "\n",
        "# Analyze ViT\n",
        "analyze_model(model_vit, input_res=(3, 224, 224), device=device)\n",
        "\n",
        "# Analyze ResNet\n",
        "analyze_model(model_resnet, input_res=(3, 224, 224), device=device)\n",
        "\n",
        "# DenseNet\n",
        "analyze_model(model_densenet, input_res=(3, 224, 224), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# EfficientNetV2\n",
        "analyze_model(model_effnetv2, input_res=(3, 224, 224), device=device)\n",
        "\n",
        "# ConvNeXt\n",
        "analyze_model(model_convnext, input_res=(3, 224, 224), device=device)\n",
        "\n",
        "# RegNet\n",
        "analyze_model(model_regnet, input_res=(3, 224, 224), device=device)\n",
        "\n",
        "# Swin Transformer\n",
        "analyze_model(model_swin, input_res=(3, 224, 224), device=device)\n",
        "\n",
        "# MaxViT\n",
        "analyze_model(model_maxvit, input_res=(3, 224, 224), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
